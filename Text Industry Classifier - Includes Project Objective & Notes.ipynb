{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import wordnet as wn\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Program Objective\\n\\n\\n1.) Target                Industry of company that is the subject of the EEOC article. \\n\\n\\n2.) Challenges            So far, it has been challenging to identify the industry of a company that has been \\n                          the subject of the EEOC Articles for which we are text mining. A general list of industry\\n                          names has not proven successful as the articles either do not include the specific name\\n                          of the industry, include a derivation, or no match at all.  In the last case, there are \\n                          certain clues in the articles such as the profession of the agreeved individual and or \\n                          an abstract mention of what the company does.\\n\\n3.) Approach              Using the list of SIC Industry keys, create a hierarchical dictionary that captures \\n                          superior, lateral as well as inferior related words.  This hierarchical approach should \\n                          have a better chance of capturing the industry value from the articles. \\n\\n4.) Program Components    a.) Industry list, b.) Dictionary tree of industries, c.) function that mines text to \\n                          find a match. \\n\\n5.) Tree Structure        a.) Obtain SIC Industry list\\n                          b.) Create Dict lvls:  Starting value is the industry. \\n                              i. root_hypernyms, ii. hypernyms, iii. synsets of industry. \\n\\n6.) Matching Function     The matching will need to take place at the synsets lvl.  If we were to start with the \\n                          hypernym, we could lose meaning.  Important - In light of the fact that multiple matches\\n                          may be obtained from any one industry, the matching function should include a voting\\n                          sub-function.  Take the count of the highest matches. In the event of a draw, maybe defer\\n                          to the industry with the highest frequency in your matches so far, else arbitrarily take\\n                          the first one in the list. \\n\\n7.) Result                a.) Object type = dataframe, b.) att1 = article, c.) att2 = root_hypernym, \\n                          d.) att3 = hypernym, e.) att4 = target / industry. \\n\\n'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Program Objective\n",
    "\n",
    "\n",
    "1.) Target                Industry of company that is the subject of the EEOC article. \n",
    "\n",
    "\n",
    "2.) Challenges            So far, it has been challenging to identify the industry of a company that has been \n",
    "                          the subject of the EEOC Articles for which we are text mining. A general list of industry\n",
    "                          names has not proven successful as the articles either do not include the specific name\n",
    "                          of the industry, include a derivation, or no match at all.  In the last case, there are \n",
    "                          certain clues in the articles such as the profession of the agreeved individual and or \n",
    "                          an abstract mention of what the company does.\n",
    "\n",
    "3.) Approach              Using the list of SIC Industry keys, create a hierarchical dictionary that captures \n",
    "                          superior, lateral as well as inferior related words.  This hierarchical approach should \n",
    "                          have a better chance of capturing the industry value from the articles. \n",
    "\n",
    "4.) Program Components    a.) Industry list, b.) Dictionary tree of industries, c.) function that mines text to \n",
    "                          find a match. \n",
    "\n",
    "5.) Tree Structure        a.) Obtain SIC Industry list\n",
    "                          b.) Create Dict lvls:  Starting value is the industry. \n",
    "                              i. root_hypernyms, ii. hypernyms, iii. synsets of industry. \n",
    "\n",
    "6.) Matching Function     The matching will need to take place at the synsets lvl.  If we were to start with the \n",
    "                          hypernym, we could lose meaning.  Important - In light of the fact that multiple matches\n",
    "                          may be obtained from any one industry, the matching function should include a voting\n",
    "                          sub-function.  Take the count of the highest matches. In the event of a draw, maybe defer\n",
    "                          to the industry with the highest frequency in your matches so far, else arbitrarily take\n",
    "                          the first one in the list. \n",
    "\n",
    "7.) Result                a.) Object type = dataframe, b.) att1 = article, c.) att2 = root_hypernym, \n",
    "                          d.) att3 = hypernym, e.) att4 = target / industry. \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Add to those industries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Stages\\n\\n1. Obtain list of industries\\n2. Obtain synset for each industry\\n3. For each synset of each industry (assume multiple synsets per industry), obtain the hypernym for each and \\n   root_hypernym. \\n4. Create matching function\\n5. Create dataframe\\n\\n'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Stages\n",
    "\n",
    "1. Obtain list of industries\n",
    "2. Obtain synset for each industry\n",
    "3. For each synset of each industry (assume multiple synsets per industry), obtain the hypernym for each and \n",
    "   root_hypernym. \n",
    "4. Create matching function\n",
    "5. Create dataframe\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSynset        Synonyms for a given word.  The wn.wordnet.synsets command takes a 'string' and returns the synsets.\\n              If you call the wn.wordnet.synset(synset) then you have access to other functions like Lemmas\\nLemmas        Synonomous words.  Object structure = word.n.01.lemma; ex = Lemma('car.n.01.auto')  \\n              If you call lemmas_names on wn.wordnet.synset(synset) it will give you a list \\n              of those names. \\n\\nhttps://plot.ly/python/tree-plots/\\n\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definitions\n",
    "'''\n",
    "Synset        Synonyms for a given word.  The wn.wordnet.synsets command takes a 'string' and returns the synsets.\n",
    "              If you call the wn.wordnet.synset(synset) then you have access to other functions like Lemmas\n",
    "Lemmas        Synonomous words.  Object structure = word.n.01.lemma; ex = Lemma('car.n.01.auto')  \n",
    "              If you call lemmas_names on wn.wordnet.synset(synset) it will give you a list \n",
    "              of those names. \n",
    "\n",
    "https://plot.ly/python/tree-plots/\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/Users/ccirelli2/Public/Python Programing Docs/Projects/Web Scraping Project - EEOC Articles')\n",
    "Url = r'EEOC Article Study - Industry Values.xlsx'\n",
    "df1 = pd.read_excel(Url)\n",
    "df2 = df1.set_index('Keys')\n",
    "df3 = df2.iloc[0:22, :]  # Limit the scope of the dataframe.  Function is picking up nan values which is causing\n",
    "                         # an error. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Industry Keys and Values\n",
    "\n",
    "def Create_Industry_Dictionary(dataframe):\n",
    "    Dict_major = {}\n",
    "    \n",
    "    # for each major industry value (column A) in the dataframe\n",
    "    for major in dataframe.index:\n",
    "        \n",
    "        # Define the minor industry as the row values. \n",
    "        df_minor = dataframe.loc[major]\n",
    "        \n",
    "        # Define the industry value lvl 2 and 3 to include in the keys of your dictionary (for descriptive purp)\n",
    "        Industry_lvl_2 = df_minor['Division']\n",
    "        Industry_lvl_3 = df_minor['Columna2']\n",
    "\n",
    "        # Define the list to catch the synsets generated by the below function. \n",
    "        Synset_list = []\n",
    "        \n",
    "        # For the value in the dataframe, the key being the value in column B 'Division'\n",
    "        for value in df_minor[1:]:\n",
    "            # Verify that it is an instance of a string as we have None values in the dataframe. \n",
    "            if isinstance(value, str):\n",
    "                # Convert the value to lowercase. \n",
    "                value_lower = value.lower()\n",
    "                # Generate synsets for this value.\n",
    "                Synset = wn.wordnet.synsets(value_lower)\n",
    "                # Extract the word from the synset object ('word.n.01')\n",
    "                Lemma_names = [x.lemma_names() for x in Synset]\n",
    "                # Lemman_names is a list of lists.  Iterate over each list. \n",
    "                for List in Lemma_names:\n",
    "                    # Get the words in each sub list. \n",
    "                    for word in List:\n",
    "                        # We want to end up with a Set of unique values.  Therefore, check to see \n",
    "                        # if the word is already in our list. \n",
    "                        if word not in Synset_list:\n",
    "                            # If not, then append the word to our list. \n",
    "                            Synset_list.append(word)\n",
    "        \n",
    "        # Create the name of the Major Industry Group that will constitute the Keys of our Dict. \n",
    "        Industry_identifier = (str(major) + ' ' + Industry_lvl_2 + ' - ' + Industry_lvl_3)\n",
    "        # Join the Keys with our matching values. \n",
    "        Dict_major[Industry_identifier] = Synset_list\n",
    "    \n",
    "    # Return our completed Industry Dictionary\n",
    "    return Dict_major\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Get Industry Function\n",
    "\n",
    "Functionality           a.) Function needs to be able to take a list of tokens from a speciment text, \n",
    "                        b.) Compare those tokens to the Industry dictionary values, \n",
    "                        c.) generate a match count by major group\n",
    "                        d.) return the major group with the highest count. \n",
    "'''    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Texts\n",
    "\n",
    "chdir = os.chdir(r'/Users/ccirelli2/Public/Python Programing Docs/Projects/Web Scraping project - EEOC Articles/EEOC Articles/')\n",
    "Cdw = os.getcwd()\n",
    "File_name_list = os.listdir()\n",
    "\n",
    "def get_Dir_list(File):\n",
    "        List = []\n",
    "        for x in File:    \n",
    "            if 'txt' in x:                                    # Confirm a txt file\n",
    "                y = Cdw + '\\\\' + x  \n",
    "                List.append(y)\n",
    "        return List\n",
    "\n",
    "Dir_list = get_Dir_list(File_name_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chdir = os.chdir(r'/Users/ccirelli2/Public/Python Programing Docs/Modules/')\n",
    "import ccirelli2_text_analysis_module as cc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_industry_count(Token_list, Industry_dict):\n",
    "    \n",
    "    ## Objective = a.) Create a dictionary that represents the count of words matched between a given text and our \n",
    "    #              industry dictionary. \n",
    "    #              b.) Take the highest count as the vote for the Industry that is most likely the topic of the\n",
    "    #              text. \n",
    "    # Token List = List of tokens/words for a particular text\n",
    "    # Dict_Industries = Dictionary create with key words that identify certain industries. \n",
    "    # Major group = Industry major group represented by a 'key' in the dictionary. \n",
    "    \n",
    "    \n",
    "    # Dictonary to organize matches for each \n",
    "    Word_match_count = {}\n",
    "    \n",
    "    # Start the matching process. \n",
    "    \n",
    "    # For each token (word) in the token list\n",
    "    for token in Token_list:  \n",
    "\n",
    "        # For each key (major group) in the Industry Dictionary\n",
    "        for major_group in Dict_Industries:                         \n",
    "                \n",
    "            # If there is a match between the word/token in our text and the value in our dictionary\n",
    "            if token in Dict_Industries[major_group]:\n",
    "                \n",
    "                # Check to see if the major group that coincides with the value in our dict is in our \n",
    "                # word_match dictionary.  if not, we need to create / define it. \n",
    "                \n",
    "                if major_group in Word_match_count.keys():\n",
    "                    \n",
    "                    # if our major group key is already in the match dict, check to see if the matching value is\n",
    "                    # already in our match dict.  Otherwise, we would need to create / define it. \n",
    "                    if token in Word_match_count[major_group]:\n",
    "                        \n",
    "                        # Given that the major group and value is in our word_match_dict, AND given that we \n",
    "                        # have a match between token and a value in the Industry_dict, add 1 to the coinciding \n",
    "                        # major_group and value.\n",
    "                        Word_match_count[major_group] = Word_match_count[major_group] + [token]\n",
    "                \n",
    "                # Given that we have a token / value match, yet the major group is NOT in the word_count_dict keys,\n",
    "                # then we need to create this key entry and assign it the value of the matching token/word. \n",
    "                else:\n",
    "                    Word_match_count[major_group] = [token]\n",
    "    \n",
    "    # For each key, value pair, take the length of the values for a given key as the # of matches for that key. \n",
    "    for x in Word_match_count:\n",
    "        Dict[x] = len(Dict[x])\n",
    "\n",
    "    # For Major Group Legal Services, take half the count to compensate for the fact that we are using legal text.\n",
    "    for x in Word_match_count:\n",
    "        if '81' in x:\n",
    "            Dict[x] = Dict[x] * 0.5           \n",
    "                                             \n",
    "    # Create a Dataframe of our Dictionary Values & Sort to rank the industry groups by num matches\n",
    "    # Keep the ranking separate from the prediction so that you can investigate the results. \n",
    "    \n",
    "    df = pd.DataFrame(Word_match_count, index = [1])\n",
    "    df_tran = pd.DataFrame.transpose(df)\n",
    "    df_sorted = df_tran.sort_values(1, ascending = False)\n",
    "    \n",
    "    return df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Industry_prediction(Obj_from_industry_classifier):\n",
    "    # Return the top row as the Prediction from our Industry Classifier function. \n",
    "    Top_row = Obj_from_industry_classifier.iloc[0]\n",
    "    Industry = Top_row.name\n",
    "    return Industry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_industry_pipeline(Text):\n",
    "    Text_tokenized = word_tokenize(Text)\n",
    "    Clean_text = cc.text_cleaning_pipeline(Text_tokenized)\n",
    "    Industry_classifier = get_industry(Clean_text, Dict_Industries_dict)\n",
    "    Industry_prediction = Industry_prediction(Industry_classifier)\n",
    "    return Industry_prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chdir = os.chdir(r'/Users/ccirelli2/Public/Python Programing Docs/Projects/Web Scraping project - EEOC Articles/EEOC Articles/')\n",
    "Url_name_list = os.listdir()\n",
    "Url = Url_name_list[2]\n",
    "File = open(Url, 'rb')\n",
    "Text = str(File.read()).lower()\n",
    "\n",
    "\n",
    "Text_tokenized = nltk.wordpunct_tokenize(Text)\n",
    "Text_nopunct = cc.strip_punctuation(Text_tokenized)\n",
    "Text_strip_slashes = cc.strip_tokens_forwardSlash_x2(Text_nopunct)\n",
    "Text_strip_two_vars = cc.strip_two_variable_tokens(Text_strip_slashes)\n",
    "Text_strip_stop_words = cc.strip_stop_words(Text_strip_two_vars)\n",
    "Text_get_isalpha = cc.get_isalpha(Text_strip_stop_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Get_industry_count = get_industry_count(Text_get_isalpha, Industry_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Major Group 81=&gt;  Services-Law firm</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major Group 73=&gt;  Services-Business Services</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major Group 82=&gt;  Services-Education</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major Group 87=&gt;  Services-Engineering</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major Group 91-99=&gt;  Services-Government</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                1\n",
       "Major Group 81=>  Services-Law firm           2.0\n",
       "Major Group 73=>  Services-Business Services  1.0\n",
       "Major Group 82=>  Services-Education          1.0\n",
       "Major Group 87=>  Services-Engineering        1.0\n",
       "Major Group 91-99=>  Services-Government      1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Get_industry_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Major Group 73=>  Services-Business Services'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Industry_prediction(Get_industry_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<div class=\"cs_control\" id=\"cs_control_4119\">\\r\\n<div align=\"left\">\\r\\n<p><em><strong>press release</strong></em><br/>\\r\\r\\n\\t1-27-10</p>\\r\\n</div>\\r\\n<div align=\"center\">\\r\\n<div class=\"caption\">\\r\\n<p></p>\\r\\n</div>\\r\\n<h1>$428,500 decree ends suit against eagle wings for sexual harassment, retaliation and disability bias</h1>\\r\\n</div>\\r\\n<div align=\"left\"><div align=\"center\"><em><strong>eeoc case challenged treatment of women at rantoul facility</strong></em><br/>\\r\\n</div>\\r\\n<p><br/>\\r\\nurbana, ill. \\x96 the federal district court in urbana, ill., today entered a consent decree under which eagle wings industries, inc. will pay $428,500 to a class of female employees who, the u.s. equal employment opportunity commission (eeoc) alleged, encountered sexual harassment at the company\\x92s rantoul, ill., facility.\\xa0 this amount includes the attorney\\x92s fees for one of the class members.<br/>\\r\\n\\xa0<br/>\\r\\naccording to the eeoc suit, the automobile parts manufacturer discriminated against a class of female employees by subjecting them to sexual harassment, retaliated against one woman for engaging in protected activity and also required one woman to undergo an unlawful medical examination, contrary to the americans with disabilities act (ada).<br/>\\r\\n<br/>\\r\\nthe eeoc filed suit, <em>eeoc v. eagle wings industries</em>, case no. 08-2231 (c.d. ill.), on september 29, 2008.\\xa0 the case was assigned to u.s. district judge michael mccuskey and magistrate judge david bernthal.\\xa0 the eeoc went to court after an administrative investigation, supervised by chicago district director john rowe, found that there was reasonable cause to believe that title vii of the civil rights act of 1964 and the ada had been violated, and after first attempting to reach a\\xa0 settlement without litigation through the agency\\x92s statutory conciliation process.\\xa0 judge mccuskey entered the consent decree on january 27.<br/>\\r\\n<br/>\\r\\nin addition to the monetary relief, eagle wings is required, under the publicly filed consent decree, to give training to employees at the rantoul facility; post a notice of the settlement there; maintain records of discrimination complaints; and report such complaints to the eeoc, together with any actions taken in response, for two years.<br/>\\r\\n<br/>\\r\\nthe government\\x92s litigation effort was led by eeoc supervisory trial attorney diane i. smason and trial attorney aaron r. decamp, under the supervision of chicago regional attorney john hendrickson.<br/>\\r\\n<br/>\\r\\nthe eeoc chicago district office is responsible for processing charges of discrimination, administrative enforcement, and the conduct of agency litigation in illinois, wisconsin, minnesota, iowa, and north and south dakota, with area offices in milwaukee and minneapolis.<br/>\\r\\n<br/>\\r\\nthe eeoc enforces federal laws prohibiting employment discrimination.\\xa0 further information about the eeoc is available on the agency\\x92s web site at www.eeoc.gov.</p></div>\\r\\n</div>'\n"
     ]
    }
   ],
   "source": [
    "print(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chdir = os.chdir(r'/Users/ccirelli2/Public/Python Programing Docs/Projects/Web Scraping project - EEOC Articles/EEOC Articles/')\n",
    "# File_name_list = os.listdir()\n",
    "\n",
    "# for x in File_name_list[:1]:\n",
    "#     File = open(x, 'rb')\n",
    "#     Text_bytes = File.read()\n",
    "#     Text_text = str(Text_bytes)\n",
    "#     predict_industry_pipeline(Text_bytes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
